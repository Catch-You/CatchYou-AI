{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vIyF3fq2rkXO"
      },
      "outputs": [],
      "source": [
        "!pip install diffusers[\"torch\"] transformers\n",
        "!pip install datasets\n",
        "!pip install git+https://github.com/huggingface/diffusers.git\n",
        "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
        "!pip install accelerate torchvision transformers datasets ftfy tensorboard Jinja2\n",
        "!pip install diffusers\n",
        "#!pip install git+https://github.com/cloneofsimo/lora.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWxLEsO5tviE",
        "outputId": "f8b787a0-b914-4809-ec2f-c780c9f3e724"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "git-lfs is already the newest version (3.0.2-1ubuntu0.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 10 not upgraded.\n",
            "git-lfs/3.0.2 (GitHub; linux amd64; go 1.18.1)\n",
            "Git LFS initialized.\n"
          ]
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%%shell\n",
        "apt install git-lfs\n",
        "git lfs version\n",
        "git lfs install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4b6Y8-C0rkZ-"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "import huggingface_hub\n",
        "\n",
        "huggingface_hub.login(\n",
        "    token= #{my_huggingface_token}\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KTarCk0oI2ep"
      },
      "outputs": [],
      "source": [
        "!pip install wandb\n",
        "import wandb\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OFH26aRuKS0_"
      },
      "outputs": [],
      "source": [
        "wandb.login(\n",
        "    key= #{my_wandb_key}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a3h1UmFKuvqT"
      },
      "outputs": [],
      "source": [
        "#%%shell\n",
        "#accelerate config default\n",
        "#!mv /root/.cache/huggingface/accelerate/default_config.yaml /content/\n",
        "#!cp /content/default_config.yaml /root/.cache/huggingface/accelerate/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfwdIy1b8T7E",
        "outputId": "7e685135-3260-44b7-e929-b10339d1dd99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c_xoai5J9CQf"
      },
      "outputs": [],
      "source": [
        "!cp /content/drive/MyDrive/Prompt2Prompt/train_text_to_image_lora.py /content/\n",
        "!cp /content/drive/MyDrive/Prompt2Prompt/default_config.yaml /content/\n",
        "#!cp /content/drive/MyDrive/Prompt2Prompt/train_text_to_image.py /content/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNPtpELa99sB",
        "outputId": "f8e4e856-fb09-49ee-9fdf-aa293e5d2559"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--num_processes` was set to a value of `1`\n",
            "\t`--num_machines` was set to a value of `1`\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "2023-11-26 13:40:16.493206: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-26 13:40:16.493264: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-26 13:40:16.493294: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-26 13:40:17.697248: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "11/26/2023 13:40:18 - INFO - __main__ - Distributed environment: NO\n",
            "Num processes: 1\n",
            "Process index: 0\n",
            "Local process index: 0\n",
            "Device: cuda\n",
            "\n",
            "Mixed precision type: fp16\n",
            "\n",
            "{'variance_type', 'prediction_type', 'dynamic_thresholding_ratio', 'sample_max_value', 'timestep_spacing', 'thresholding', 'clip_sample_range'} was not found in config. Values will be initialized to default values.\n",
            "{'force_upcast', 'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
            "{'addition_embed_type_num_heads', 'conv_in_kernel', 'resnet_out_scale_factor', 'num_class_embeds', 'upcast_attention', 'time_embedding_act_fn', 'cross_attention_norm', 'use_linear_projection', 'dual_cross_attention', 'resnet_time_scale_shift', 'time_embedding_dim', 'transformer_layers_per_block', 'attention_type', 'encoder_hid_dim_type', 'dropout', 'reverse_transformer_layers_per_block', 'addition_embed_type', 'timestep_post_act', 'only_cross_attention', 'mid_block_only_cross_attention', 'resnet_skip_time_act', 'projection_class_embeddings_input_dim', 'class_embed_type', 'encoder_hid_dim', 'num_attention_heads', 'addition_time_embed_dim', 'class_embeddings_concat', 'conv_out_kernel', 'time_embedding_type', 'mid_block_type', 'time_cond_proj_dim'} was not found in config. Values will be initialized to default values.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msujinhwang\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20231126_134028-78xgw0eh\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfearless-plasma-64\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/sujinhwang/text2image-fine-tune\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/sujinhwang/text2image-fine-tune/runs/78xgw0eh\u001b[0m\n",
            "11/26/2023 13:40:29 - INFO - __main__ - ***** Running training *****\n",
            "11/26/2023 13:40:29 - INFO - __main__ -   Num examples = 8071\n",
            "11/26/2023 13:40:29 - INFO - __main__ -   Num Epochs = 8\n",
            "11/26/2023 13:40:29 - INFO - __main__ -   Instantaneous batch size per device = 1\n",
            "11/26/2023 13:40:29 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
            "11/26/2023 13:40:29 - INFO - __main__ -   Gradient Accumulation steps = 4\n",
            "11/26/2023 13:40:29 - INFO - __main__ -   Total optimization steps = 15000\n",
            "Steps:   0% 0/15000 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/diffusers/models/attention_processor.py:1746: FutureWarning: `LoRAAttnProcessor` is deprecated and will be removed in version 0.26.0. Make sure use AttnProcessor instead by settingLoRA layers to `self.{to_q,to_k,to_v,to_out[0]}.lora_layer` respectively. This will be done automatically when using `LoraLoaderMixin.load_lora_weights`\n",
            "  deprecate(\n",
            "Steps:  13% 2018/15000 [2:44:06<16:29:48,  4.57s/it, lr=0.000382, step_loss=0.361] 11/26/2023 16:24:35 - INFO - __main__ - Running validation... \n",
            " Generating 4 images with prompt: ÎÇ®ÏÑ±. 30ÎåÄ. ÏñºÍµ¥ÏùÄ Í≥ÑÎûÄÌòïÏù¥Í≥† ÌÑ±ÏùÄ Îë•Í∑ºÌòïÏù¥Îã§. Í¥ëÎåÄÍ∞Ä ÎÇòÏôîÎã§. ÏßßÏùÄ Î®∏Î¶¨Ïù¥Í≥† ÎààÏçπÏù¥ ÏßÑÌïòÍ≥† ÏûëÏùÄ ÎààÏóê ÌåîÏûêÏ£ºÎ¶ÑÏù¥ ÏûàÎã§. .\n",
            "safety_checker/model.safetensors not found\n",
            "{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
            "\n",
            "Loading pipeline components...:   0% 0/7 [00:00<?, ?it/s]\u001b[A`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
            "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
            "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n",
            "Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of Bingsu/my-korean-stable-diffusion-v1-5.\n",
            "\n",
            "Loading pipeline components...:  14% 1/7 [00:02<00:13,  2.30s/it]\u001b[ALoaded text_encoder as CLIPTextModel from `text_encoder` subfolder of Bingsu/my-korean-stable-diffusion-v1-5.\n",
            "\n",
            "Loading pipeline components...:  29% 2/7 [00:02<00:06,  1.36s/it]\u001b[A{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of Bingsu/my-korean-stable-diffusion-v1-5.\n",
            "Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of Bingsu/my-korean-stable-diffusion-v1-5.\n",
            "Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of Bingsu/my-korean-stable-diffusion-v1-5.\n",
            "\n",
            "Loading pipeline components...:  86% 6/7 [00:03<00:00,  3.00it/s]\u001b[A{'force_upcast'} was not found in config. Values will be initialized to default values.\n",
            "Loaded vae as AutoencoderKL from `vae` subfolder of Bingsu/my-korean-stable-diffusion-v1-5.\n",
            "Loading pipeline components...: 100% 7/7 [00:03<00:00,  2.12it/s]\n",
            "Steps:  27% 4036/15000 [5:28:58<13:56:28,  4.58s/it, lr=0.000333, step_loss=0.00759]11/26/2023 19:09:27 - INFO - __main__ - Running validation... \n",
            " Generating 4 images with prompt: ÎÇ®ÏÑ±. 30ÎåÄ. ÏñºÍµ¥ÏùÄ Í≥ÑÎûÄÌòïÏù¥Í≥† ÌÑ±ÏùÄ Îë•Í∑ºÌòïÏù¥Îã§. Í¥ëÎåÄÍ∞Ä ÎÇòÏôîÎã§. ÏßßÏùÄ Î®∏Î¶¨Ïù¥Í≥† ÎààÏçπÏù¥ ÏßÑÌïòÍ≥† ÏûëÏùÄ ÎààÏóê ÌåîÏûêÏ£ºÎ¶ÑÏù¥ ÏûàÎã§. .\n",
            "safety_checker/model.safetensors not found\n",
            "{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
            "\n",
            "Loading pipeline components...:   0% 0/7 [00:00<?, ?it/s]\u001b[A`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
            "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
            "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n",
            "Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of Bingsu/my-korean-stable-diffusion-v1-5.\n",
            "\n",
            "Loading pipeline components...:  14% 1/7 [00:01<00:11,  1.98s/it]\u001b[ALoaded text_encoder as CLIPTextModel from `text_encoder` subfolder of Bingsu/my-korean-stable-diffusion-v1-5.\n",
            "\n",
            "Loading pipeline components...:  29% 2/7 [00:02<00:05,  1.18s/it]\u001b[A{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of Bingsu/my-korean-stable-diffusion-v1-5.\n",
            "Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of Bingsu/my-korean-stable-diffusion-v1-5.\n",
            "Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of Bingsu/my-korean-stable-diffusion-v1-5.\n",
            "\n",
            "Loading pipeline components...:  86% 6/7 [00:02<00:00,  3.42it/s]\u001b[A{'force_upcast'} was not found in config. Values will be initialized to default values.\n",
            "Loaded vae as AutoencoderKL from `vae` subfolder of Bingsu/my-korean-stable-diffusion-v1-5.\n",
            "Loading pipeline components...: 100% 7/7 [00:02<00:00,  2.42it/s]\n",
            "Steps:  40% 6054/15000 [8:13:59<11:24:21,  4.59s/it, lr=0.00026, step_loss=0.0973] 11/26/2023 21:54:28 - INFO - __main__ - Running validation... \n",
            " Generating 4 images with prompt: ÎÇ®ÏÑ±. 30ÎåÄ. ÏñºÍµ¥ÏùÄ Í≥ÑÎûÄÌòïÏù¥Í≥† ÌÑ±ÏùÄ Îë•Í∑ºÌòïÏù¥Îã§. Í¥ëÎåÄÍ∞Ä ÎÇòÏôîÎã§. ÏßßÏùÄ Î®∏Î¶¨Ïù¥Í≥† ÎààÏçπÏù¥ ÏßÑÌïòÍ≥† ÏûëÏùÄ ÎààÏóê ÌåîÏûêÏ£ºÎ¶ÑÏù¥ ÏûàÎã§. .\n",
            "safety_checker/model.safetensors not found\n",
            "{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
            "\n",
            "Loading pipeline components...:   0% 0/7 [00:00<?, ?it/s]\u001b[A`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
            "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
            "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n",
            "Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of Bingsu/my-korean-stable-diffusion-v1-5.\n",
            "\n",
            "Loading pipeline components...:  14% 1/7 [00:02<00:12,  2.04s/it]\u001b[ALoaded text_encoder as CLIPTextModel from `text_encoder` subfolder of Bingsu/my-korean-stable-diffusion-v1-5.\n",
            "\n",
            "Loading pipeline components...:  29% 2/7 [00:02<00:06,  1.21s/it]\u001b[A{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of Bingsu/my-korean-stable-diffusion-v1-5.\n",
            "Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of Bingsu/my-korean-stable-diffusion-v1-5.\n",
            "Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of Bingsu/my-korean-stable-diffusion-v1-5.\n",
            "\n",
            "Loading pipeline components...:  86% 6/7 [00:02<00:00,  3.32it/s]\u001b[A{'force_upcast'} was not found in config. Values will be initialized to default values.\n",
            "Loaded vae as AutoencoderKL from `vae` subfolder of Bingsu/my-korean-stable-diffusion-v1-5.\n",
            "Loading pipeline components...: 100% 7/7 [00:02<00:00,  2.35it/s]\n",
            "Steps:  54% 8072/15000 [10:59:14<8:50:11,  4.59s/it, lr=0.000176, step_loss=0.485]  11/27/2023 00:39:44 - INFO - __main__ - Running validation... \n",
            " Generating 4 images with prompt: ÎÇ®ÏÑ±. 30ÎåÄ. ÏñºÍµ¥ÏùÄ Í≥ÑÎûÄÌòïÏù¥Í≥† ÌÑ±ÏùÄ Îë•Í∑ºÌòïÏù¥Îã§. Í¥ëÎåÄÍ∞Ä ÎÇòÏôîÎã§. ÏßßÏùÄ Î®∏Î¶¨Ïù¥Í≥† ÎààÏçπÏù¥ ÏßÑÌïòÍ≥† ÏûëÏùÄ ÎààÏóê ÌåîÏûêÏ£ºÎ¶ÑÏù¥ ÏûàÎã§. .\n",
            "safety_checker/model.safetensors not found\n",
            "{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
            "\n",
            "Loading pipeline components...:   0% 0/7 [00:00<?, ?it/s]\u001b[A`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
            "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
            "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n",
            "Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of Bingsu/my-korean-stable-diffusion-v1-5.\n",
            "\n",
            "Loading pipeline components...:  14% 1/7 [00:02<00:12,  2.11s/it]\u001b[ALoaded text_encoder as CLIPTextModel from `text_encoder` subfolder of Bingsu/my-korean-stable-diffusion-v1-5.\n",
            "\n",
            "Loading pipeline components...:  29% 2/7 [00:02<00:06,  1.24s/it]\u001b[A{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of Bingsu/my-korean-stable-diffusion-v1-5.\n",
            "Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of Bingsu/my-korean-stable-diffusion-v1-5.\n",
            "Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of Bingsu/my-korean-stable-diffusion-v1-5.\n",
            "\n",
            "Loading pipeline components...:  86% 6/7 [00:02<00:00,  3.25it/s]\u001b[A{'force_upcast'} was not found in config. Values will be initialized to default values.\n",
            "Loaded vae as AutoencoderKL from `vae` subfolder of Bingsu/my-korean-stable-diffusion-v1-5.\n",
            "Loading pipeline components...: 100% 7/7 [00:03<00:00,  2.30it/s]\n",
            "Steps:  67% 10090/15000 [13:44:34<6:14:51,  4.58s/it, lr=9.68e-5, step_loss=0.00987]11/27/2023 03:25:04 - INFO - __main__ - Running validation... \n",
            " Generating 4 images with prompt: ÎÇ®ÏÑ±. 30ÎåÄ. ÏñºÍµ¥ÏùÄ Í≥ÑÎûÄÌòïÏù¥Í≥† ÌÑ±ÏùÄ Îë•Í∑ºÌòïÏù¥Îã§. Í¥ëÎåÄÍ∞Ä ÎÇòÏôîÎã§. ÏßßÏùÄ Î®∏Î¶¨Ïù¥Í≥† ÎààÏçπÏù¥ ÏßÑÌïòÍ≥† ÏûëÏùÄ ÎààÏóê ÌåîÏûêÏ£ºÎ¶ÑÏù¥ ÏûàÎã§. .\n",
            "safety_checker/model.safetensors not found\n",
            "{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
            "\n",
            "Loading pipeline components...:   0% 0/7 [00:00<?, ?it/s]\u001b[A`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
            "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
            "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n",
            "Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of Bingsu/my-korean-stable-diffusion-v1-5.\n",
            "\n",
            "Loading pipeline components...:  14% 1/7 [00:01<00:11,  1.93s/it]\u001b[ALoaded text_encoder as CLIPTextModel from `text_encoder` subfolder of Bingsu/my-korean-stable-diffusion-v1-5.\n",
            "\n",
            "Loading pipeline components...:  29% 2/7 [00:02<00:05,  1.16s/it]\u001b[A{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of Bingsu/my-korean-stable-diffusion-v1-5.\n",
            "Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of Bingsu/my-korean-stable-diffusion-v1-5.\n",
            "Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of Bingsu/my-korean-stable-diffusion-v1-5.\n",
            "\n",
            "Loading pipeline components...:  86% 6/7 [00:02<00:00,  3.47it/s]\u001b[A{'force_upcast'} was not found in config. Values will be initialized to default values.\n",
            "Loaded vae as AutoencoderKL from `vae` subfolder of Bingsu/my-korean-stable-diffusion-v1-5.\n",
            "Loading pipeline components...: 100% 7/7 [00:02<00:00,  2.46it/s]\n",
            "Steps:  81% 12108/15000 [16:29:58<3:41:25,  4.59s/it, lr=3.56e-5, step_loss=0.00144]11/27/2023 06:10:27 - INFO - __main__ - Running validation... \n",
            " Generating 4 images with prompt: ÎÇ®ÏÑ±. 30ÎåÄ. ÏñºÍµ¥ÏùÄ Í≥ÑÎûÄÌòïÏù¥Í≥† ÌÑ±ÏùÄ Îë•Í∑ºÌòïÏù¥Îã§. Í¥ëÎåÄÍ∞Ä ÎÇòÏôîÎã§. ÏßßÏùÄ Î®∏Î¶¨Ïù¥Í≥† ÎààÏçπÏù¥ ÏßÑÌïòÍ≥† ÏûëÏùÄ ÎààÏóê ÌåîÏûêÏ£ºÎ¶ÑÏù¥ ÏûàÎã§. .\n",
            "safety_checker/model.safetensors not found\n",
            "{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
            "\n",
            "Loading pipeline components...:   0% 0/7 [00:00<?, ?it/s]\u001b[A`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
            "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
            "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n",
            "Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of Bingsu/my-korean-stable-diffusion-v1-5.\n",
            "\n",
            "Loading pipeline components...:  14% 1/7 [00:01<00:10,  1.77s/it]\u001b[ALoaded text_encoder as CLIPTextModel from `text_encoder` subfolder of Bingsu/my-korean-stable-diffusion-v1-5.\n",
            "\n",
            "Loading pipeline components...:  29% 2/7 [00:02<00:05,  1.14s/it]\u001b[A{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of Bingsu/my-korean-stable-diffusion-v1-5.\n",
            "Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of Bingsu/my-korean-stable-diffusion-v1-5.\n",
            "Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of Bingsu/my-korean-stable-diffusion-v1-5.\n",
            "\n",
            "Loading pipeline components...:  86% 6/7 [00:02<00:00,  3.52it/s]\u001b[A{'force_upcast'} was not found in config. Values will be initialized to default values.\n",
            "Loaded vae as AutoencoderKL from `vae` subfolder of Bingsu/my-korean-stable-diffusion-v1-5.\n",
            "Loading pipeline components...: 100% 7/7 [00:02<00:00,  2.52it/s]\n",
            "Steps:  94% 14126/15000 [19:15:30<1:07:14,  4.62s/it, lr=3.34e-6, step_loss=0.0127]11/27/2023 08:55:59 - INFO - __main__ - Running validation... \n",
            " Generating 4 images with prompt: ÎÇ®ÏÑ±. 30ÎåÄ. ÏñºÍµ¥ÏùÄ Í≥ÑÎûÄÌòïÏù¥Í≥† ÌÑ±ÏùÄ Îë•Í∑ºÌòïÏù¥Îã§. Í¥ëÎåÄÍ∞Ä ÎÇòÏôîÎã§. ÏßßÏùÄ Î®∏Î¶¨Ïù¥Í≥† ÎààÏçπÏù¥ ÏßÑÌïòÍ≥† ÏûëÏùÄ ÎààÏóê ÌåîÏûêÏ£ºÎ¶ÑÏù¥ ÏûàÎã§. .\n",
            "safety_checker/model.safetensors not found\n",
            "{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
            "\n",
            "Loading pipeline components...:   0% 0/7 [00:00<?, ?it/s]\u001b[A`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
            "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
            "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n",
            "Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of Bingsu/my-korean-stable-diffusion-v1-5.\n",
            "\n",
            "Loading pipeline components...:  14% 1/7 [00:01<00:11,  1.85s/it]\u001b[ALoaded text_encoder as CLIPTextModel from `text_encoder` subfolder of Bingsu/my-korean-stable-diffusion-v1-5.\n",
            "\n",
            "Loading pipeline components...:  29% 2/7 [00:02<00:05,  1.14s/it]\u001b[A{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of Bingsu/my-korean-stable-diffusion-v1-5.\n",
            "Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of Bingsu/my-korean-stable-diffusion-v1-5.\n",
            "Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of Bingsu/my-korean-stable-diffusion-v1-5.\n",
            "\n",
            "Loading pipeline components...:  86% 6/7 [00:02<00:00,  3.51it/s]\u001b[A{'force_upcast'} was not found in config. Values will be initialized to default values.\n",
            "Loaded vae as AutoencoderKL from `vae` subfolder of Bingsu/my-korean-stable-diffusion-v1-5.\n",
            "Loading pipeline components...: 100% 7/7 [00:02<00:00,  2.49it/s]\n",
            "Steps: 100% 15000/15000 [20:27:36<00:00,  4.92s/it, lr=4.39e-12, step_loss=0.15]11/27/2023 10:08:06 - INFO - accelerate.accelerator - Saving current state to criminal-sketch-lora-v2-3/checkpoint-15000\n",
            "11/27/2023 10:08:06 - INFO - accelerate.checkpointing - Model weights saved in criminal-sketch-lora-v2-3/checkpoint-15000/pytorch_model.bin\n",
            "11/27/2023 10:08:06 - INFO - accelerate.checkpointing - Optimizer state saved in criminal-sketch-lora-v2-3/checkpoint-15000/optimizer.bin\n",
            "11/27/2023 10:08:06 - INFO - accelerate.checkpointing - Scheduler state saved in criminal-sketch-lora-v2-3/checkpoint-15000/scheduler.bin\n",
            "11/27/2023 10:08:06 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in criminal-sketch-lora-v2-3/checkpoint-15000/sampler.bin\n",
            "11/27/2023 10:08:06 - INFO - accelerate.checkpointing - Gradient scaler state saved in criminal-sketch-lora-v2-3/checkpoint-15000/scaler.pt\n",
            "11/27/2023 10:08:06 - INFO - accelerate.checkpointing - Random states saved in criminal-sketch-lora-v2-3/checkpoint-15000/random_states_0.pkl\n",
            "11/27/2023 10:08:06 - INFO - __main__ - Saved state to criminal-sketch-lora-v2-3/checkpoint-15000\n",
            "Steps: 100% 15000/15000 [20:27:36<00:00,  4.92s/it, lr=0, step_loss=0.0516]     11/27/2023 10:08:06 - INFO - __main__ - Running validation... \n",
            " Generating 4 images with prompt: ÎÇ®ÏÑ±. 30ÎåÄ. ÏñºÍµ¥ÏùÄ Í≥ÑÎûÄÌòïÏù¥Í≥† ÌÑ±ÏùÄ Îë•Í∑ºÌòïÏù¥Îã§. Í¥ëÎåÄÍ∞Ä ÎÇòÏôîÎã§. ÏßßÏùÄ Î®∏Î¶¨Ïù¥Í≥† ÎààÏçπÏù¥ ÏßÑÌïòÍ≥† ÏûëÏùÄ ÎààÏóê ÌåîÏûêÏ£ºÎ¶ÑÏù¥ ÏûàÎã§. .\n",
            "safety_checker/model.safetensors not found\n",
            "{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
            "\n",
            "Loading pipeline components...:   0% 0/7 [00:00<?, ?it/s]\u001b[A`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
            "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
            "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n",
            "Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of Bingsu/my-korean-stable-diffusion-v1-5.\n",
            "\n",
            "Loading pipeline components...:  14% 1/7 [00:01<00:11,  1.88s/it]\u001b[ALoaded text_encoder as CLIPTextModel from `text_encoder` subfolder of Bingsu/my-korean-stable-diffusion-v1-5.\n",
            "\n",
            "Loading pipeline components...:  29% 2/7 [00:02<00:05,  1.16s/it]\u001b[A{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of Bingsu/my-korean-stable-diffusion-v1-5.\n",
            "Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of Bingsu/my-korean-stable-diffusion-v1-5.\n",
            "Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of Bingsu/my-korean-stable-diffusion-v1-5.\n",
            "\n",
            "Loading pipeline components...:  86% 6/7 [00:02<00:00,  3.42it/s]\u001b[A{'force_upcast'} was not found in config. Values will be initialized to default values.\n",
            "Loaded vae as AutoencoderKL from `vae` subfolder of Bingsu/my-korean-stable-diffusion-v1-5.\n",
            "Loading pipeline components...: 100% 7/7 [00:02<00:00,  2.43it/s]\n",
            "Model weights saved in criminal-sketch-lora-v2-3/pytorch_lora_weights.safetensors\n",
            "\n",
            "pytorch_model.bin:   0% 0.00/3.29M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "scaler.pt:   0% 0.00/988 [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "optimizer.bin:   0% 0.00/6.59M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scheduler.bin:   0% 0.00/1.00k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "random_states_0.pkl:   0% 0.00/14.4k [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Upload 6 LFS files:   0% 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model.bin:   0% 16.4k/3.29M [00:00<02:26, 22.3kB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "scaler.pt: 100% 988/988 [00:00<00:00, 1.33kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "optimizer.bin:   0% 16.4k/6.59M [00:00<04:57, 22.1kB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scheduler.bin: 100% 1.00k/1.00k [00:00<00:00, 1.32kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "random_states_0.pkl: 100% 14.4k/14.4k [00:00<00:00, 19.1kB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "random_states_0.pkl: 100% 14.4k/14.4k [00:00<00:00, 16.1kB/s]\n",
            "\n",
            "\n",
            "\n",
            "scheduler.bin: 100% 1.00k/1.00k [00:01<00:00, 881B/s]  \n",
            "scaler.pt: 100% 988/988 [00:01<00:00, 844B/s]  \n",
            "\n",
            "\n",
            "pytorch_model.bin: 100% 3.29M/3.29M [00:01<00:00, 2.11MB/s]\n",
            "pytorch_lora_weights.safetensors: 100% 3.23M/3.23M [00:00<00:00, 6.33MB/s]\n",
            "optimizer.bin: 100% 6.59M/6.59M [00:01<00:00, 3.57MB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Upload 6 LFS files: 100% 6/6 [00:02<00:00,  2.92it/s]\n",
            "safety_checker/model.safetensors not found\n",
            "{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
            "\n",
            "Loading pipeline components...:   0% 0/7 [00:00<?, ?it/s]\u001b[A`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
            "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
            "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n",
            "Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of Bingsu/my-korean-stable-diffusion-v1-5.\n",
            "\n",
            "Loading pipeline components...:  14% 1/7 [00:01<00:07,  1.20s/it]\u001b[ALoaded text_encoder as CLIPTextModel from `text_encoder` subfolder of Bingsu/my-korean-stable-diffusion-v1-5.\n",
            "\n",
            "Loading pipeline components...:  29% 2/7 [00:01<00:04,  1.15it/s]\u001b[A{'addition_embed_type_num_heads', 'conv_in_kernel', 'resnet_out_scale_factor', 'num_class_embeds', 'upcast_attention', 'time_embedding_act_fn', 'cross_attention_norm', 'use_linear_projection', 'dual_cross_attention', 'resnet_time_scale_shift', 'time_embedding_dim', 'transformer_layers_per_block', 'attention_type', 'encoder_hid_dim_type', 'dropout', 'reverse_transformer_layers_per_block', 'addition_embed_type', 'timestep_post_act', 'only_cross_attention', 'mid_block_only_cross_attention', 'resnet_skip_time_act', 'projection_class_embeddings_input_dim', 'class_embed_type', 'encoder_hid_dim', 'num_attention_heads', 'addition_time_embed_dim', 'class_embeddings_concat', 'conv_out_kernel', 'time_embedding_type', 'mid_block_type', 'time_cond_proj_dim'} was not found in config. Values will be initialized to default values.\n",
            "Loaded unet as UNet2DConditionModel from `unet` subfolder of Bingsu/my-korean-stable-diffusion-v1-5.\n",
            "\n",
            "Loading pipeline components...:  43% 3/7 [00:05<00:07,  1.96s/it]\u001b[A{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of Bingsu/my-korean-stable-diffusion-v1-5.\n",
            "Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of Bingsu/my-korean-stable-diffusion-v1-5.\n",
            "Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of Bingsu/my-korean-stable-diffusion-v1-5.\n",
            "\n",
            "Loading pipeline components...:  86% 6/7 [00:05<00:00,  1.45it/s]\u001b[A{'force_upcast'} was not found in config. Values will be initialized to default values.\n",
            "Loaded vae as AutoencoderKL from `vae` subfolder of Bingsu/my-korean-stable-diffusion-v1-5.\n",
            "Loading pipeline components...: 100% 7/7 [00:05<00:00,  1.29it/s]\n",
            "\n",
            "  0% 0/30 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 1/30 [00:00<00:10,  2.75it/s]\u001b[A\n",
            "  7% 2/30 [00:00<00:06,  4.16it/s]\u001b[A\n",
            " 10% 3/30 [00:00<00:05,  4.95it/s]\u001b[A\n",
            " 13% 4/30 [00:00<00:04,  5.45it/s]\u001b[A\n",
            " 17% 5/30 [00:00<00:04,  5.77it/s]\u001b[A\n",
            " 20% 6/30 [00:01<00:04,  5.98it/s]\u001b[A\n",
            " 23% 7/30 [00:01<00:03,  6.13it/s]\u001b[A\n",
            " 27% 8/30 [00:01<00:03,  6.21it/s]\u001b[A\n",
            " 30% 9/30 [00:01<00:03,  6.27it/s]\u001b[A\n",
            " 33% 10/30 [00:01<00:03,  6.31it/s]\u001b[A\n",
            " 37% 11/30 [00:01<00:03,  6.32it/s]\u001b[A\n",
            " 40% 12/30 [00:02<00:02,  6.33it/s]\u001b[A\n",
            " 43% 13/30 [00:02<00:02,  6.35it/s]\u001b[A\n",
            " 47% 14/30 [00:02<00:02,  6.36it/s]\u001b[A\n",
            " 50% 15/30 [00:02<00:02,  6.37it/s]\u001b[A\n",
            " 53% 16/30 [00:02<00:02,  6.38it/s]\u001b[A\n",
            " 57% 17/30 [00:02<00:02,  6.40it/s]\u001b[A\n",
            " 60% 18/30 [00:03<00:01,  6.42it/s]\u001b[A\n",
            " 63% 19/30 [00:03<00:01,  6.43it/s]\u001b[A\n",
            " 67% 20/30 [00:03<00:01,  6.41it/s]\u001b[A\n",
            " 70% 21/30 [00:03<00:01,  6.40it/s]\u001b[A\n",
            " 73% 22/30 [00:03<00:01,  6.39it/s]\u001b[A\n",
            " 77% 23/30 [00:03<00:01,  6.37it/s]\u001b[A\n",
            " 80% 24/30 [00:03<00:00,  6.36it/s]\u001b[A\n",
            " 83% 25/30 [00:04<00:00,  6.38it/s]\u001b[A\n",
            " 87% 26/30 [00:04<00:00,  6.38it/s]\u001b[A\n",
            " 90% 27/30 [00:04<00:00,  6.39it/s]\u001b[A\n",
            " 93% 28/30 [00:04<00:00,  6.37it/s]\u001b[A\n",
            " 97% 29/30 [00:04<00:00,  6.39it/s]\u001b[A\n",
            "100% 30/30 [00:04<00:00,  6.13it/s]\n",
            "\n",
            "  0% 0/30 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 1/30 [00:00<00:08,  3.29it/s]\u001b[A\n",
            "  7% 2/30 [00:00<00:06,  4.60it/s]\u001b[A\n",
            " 10% 3/30 [00:00<00:05,  5.25it/s]\u001b[A\n",
            " 13% 4/30 [00:00<00:04,  5.65it/s]\u001b[A\n",
            " 17% 5/30 [00:00<00:04,  5.77it/s]\u001b[A\n",
            " 20% 6/30 [00:01<00:04,  5.96it/s]\u001b[A\n",
            " 23% 7/30 [00:01<00:03,  6.10it/s]\u001b[A\n",
            " 27% 8/30 [00:01<00:03,  6.19it/s]\u001b[A\n",
            " 30% 9/30 [00:01<00:03,  6.23it/s]\u001b[A\n",
            " 33% 10/30 [00:01<00:03,  6.28it/s]\u001b[A\n",
            " 37% 11/30 [00:01<00:03,  6.30it/s]\u001b[A\n",
            " 40% 12/30 [00:02<00:02,  6.31it/s]\u001b[A\n",
            " 43% 13/30 [00:02<00:02,  6.33it/s]\u001b[A\n",
            " 47% 14/30 [00:02<00:02,  6.33it/s]\u001b[A\n",
            " 50% 15/30 [00:02<00:02,  6.34it/s]\u001b[A\n",
            " 53% 16/30 [00:02<00:02,  6.33it/s]\u001b[A\n",
            " 57% 17/30 [00:02<00:02,  6.34it/s]\u001b[A\n",
            " 60% 18/30 [00:02<00:01,  6.34it/s]\u001b[A\n",
            " 63% 19/30 [00:03<00:01,  6.34it/s]\u001b[A\n",
            " 67% 20/30 [00:03<00:01,  6.34it/s]\u001b[A\n",
            " 70% 21/30 [00:03<00:01,  6.35it/s]\u001b[A\n",
            " 73% 22/30 [00:03<00:01,  6.33it/s]\u001b[A\n",
            " 77% 23/30 [00:03<00:01,  6.31it/s]\u001b[A\n",
            " 80% 24/30 [00:03<00:00,  6.33it/s]\u001b[A\n",
            " 83% 25/30 [00:04<00:00,  6.33it/s]\u001b[A\n",
            " 87% 26/30 [00:04<00:00,  6.29it/s]\u001b[A\n",
            " 90% 27/30 [00:04<00:00,  6.27it/s]\u001b[A\n",
            " 93% 28/30 [00:04<00:00,  6.31it/s]\u001b[A\n",
            " 97% 29/30 [00:04<00:00,  6.29it/s]\u001b[A\n",
            "100% 30/30 [00:04<00:00,  6.13it/s]\n",
            "\n",
            "  0% 0/30 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 1/30 [00:00<00:08,  3.25it/s]\u001b[A\n",
            "  7% 2/30 [00:00<00:06,  4.55it/s]\u001b[A\n",
            " 10% 3/30 [00:00<00:05,  5.24it/s]\u001b[A\n",
            " 13% 4/30 [00:00<00:04,  5.61it/s]\u001b[A\n",
            " 17% 5/30 [00:00<00:04,  5.69it/s]\u001b[A\n",
            " 20% 6/30 [00:01<00:04,  5.91it/s]\u001b[A\n",
            " 23% 7/30 [00:01<00:03,  6.03it/s]\u001b[A\n",
            " 27% 8/30 [00:01<00:03,  6.11it/s]\u001b[A\n",
            " 30% 9/30 [00:01<00:03,  6.13it/s]\u001b[A\n",
            " 33% 10/30 [00:01<00:03,  6.15it/s]\u001b[A\n",
            " 37% 11/30 [00:01<00:03,  6.19it/s]\u001b[A\n",
            " 40% 12/30 [00:02<00:02,  6.21it/s]\u001b[A\n",
            " 43% 13/30 [00:02<00:02,  6.21it/s]\u001b[A\n",
            " 47% 14/30 [00:02<00:02,  6.24it/s]\u001b[A\n",
            " 50% 15/30 [00:02<00:02,  6.26it/s]\u001b[A\n",
            " 53% 16/30 [00:02<00:02,  6.26it/s]\u001b[A\n",
            " 57% 17/30 [00:02<00:02,  6.26it/s]\u001b[A\n",
            " 60% 18/30 [00:03<00:01,  6.28it/s]\u001b[A\n",
            " 63% 19/30 [00:03<00:01,  6.27it/s]\u001b[A\n",
            " 67% 20/30 [00:03<00:01,  6.26it/s]\u001b[A\n",
            " 70% 21/30 [00:03<00:01,  6.26it/s]\u001b[A\n",
            " 73% 22/30 [00:03<00:01,  6.25it/s]\u001b[A\n",
            " 77% 23/30 [00:03<00:01,  6.27it/s]\u001b[A\n",
            " 80% 24/30 [00:03<00:00,  6.26it/s]\u001b[A\n",
            " 83% 25/30 [00:04<00:00,  6.27it/s]\u001b[A\n",
            " 87% 26/30 [00:04<00:00,  6.26it/s]\u001b[A\n",
            " 90% 27/30 [00:04<00:00,  6.28it/s]\u001b[A\n",
            " 93% 28/30 [00:04<00:00,  6.25it/s]\u001b[A\n",
            " 97% 29/30 [00:04<00:00,  6.24it/s]\u001b[A\n",
            "100% 30/30 [00:04<00:00,  6.06it/s]\n",
            "\n",
            "  0% 0/30 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 1/30 [00:00<00:09,  3.22it/s]\u001b[A\n",
            "  7% 2/30 [00:00<00:06,  4.53it/s]\u001b[A\n",
            " 10% 3/30 [00:00<00:05,  5.21it/s]\u001b[A\n",
            " 13% 4/30 [00:00<00:04,  5.56it/s]\u001b[A\n",
            " 17% 5/30 [00:00<00:04,  5.66it/s]\u001b[A\n",
            " 20% 6/30 [00:01<00:04,  5.87it/s]\u001b[A\n",
            " 23% 7/30 [00:01<00:03,  6.00it/s]\u001b[A\n",
            " 27% 8/30 [00:01<00:03,  6.08it/s]\u001b[A\n",
            " 30% 9/30 [00:01<00:03,  6.13it/s]\u001b[A\n",
            " 33% 10/30 [00:01<00:03,  6.15it/s]\u001b[A\n",
            " 37% 11/30 [00:01<00:03,  6.13it/s]\u001b[A\n",
            " 40% 12/30 [00:02<00:02,  6.13it/s]\u001b[A\n",
            " 43% 13/30 [00:02<00:02,  6.15it/s]\u001b[A\n",
            " 47% 14/30 [00:02<00:02,  6.16it/s]\u001b[A\n",
            " 50% 15/30 [00:02<00:02,  6.17it/s]\u001b[A\n",
            " 53% 16/30 [00:02<00:02,  6.18it/s]\u001b[A\n",
            " 57% 17/30 [00:02<00:02,  6.18it/s]\u001b[A\n",
            " 60% 18/30 [00:03<00:01,  6.16it/s]\u001b[A\n",
            " 63% 19/30 [00:03<00:01,  6.16it/s]\u001b[A\n",
            " 67% 20/30 [00:03<00:01,  6.17it/s]\u001b[A\n",
            " 70% 21/30 [00:03<00:01,  6.17it/s]\u001b[A\n",
            " 73% 22/30 [00:03<00:01,  6.18it/s]\u001b[A\n",
            " 77% 23/30 [00:03<00:01,  6.19it/s]\u001b[A\n",
            " 80% 24/30 [00:04<00:00,  6.16it/s]\u001b[A\n",
            " 83% 25/30 [00:04<00:00,  6.17it/s]\u001b[A\n",
            " 87% 26/30 [00:04<00:00,  6.18it/s]\u001b[A\n",
            " 90% 27/30 [00:04<00:00,  6.17it/s]\u001b[A\n",
            " 93% 28/30 [00:04<00:00,  6.18it/s]\u001b[A\n",
            " 97% 29/30 [00:04<00:00,  6.16it/s]\u001b[A\n",
            "100% 30/30 [00:05<00:00,  6.00it/s]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss ‚ñÅ‚ñÇ‚ñÖ‚ñÇ‚ñÖ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñà‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÜ‚ñÇ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÑ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÉ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 0.11841\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33mfearless-plasma-64\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/sujinhwang/text2image-fine-tune/runs/78xgw0eh\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 36 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20231126_134028-78xgw0eh/logs\u001b[0m\n",
            "/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py:2163: UserWarning: Run (78xgw0eh) is finished. The call to `_console_raw_callback` will be ignored. Please make sure that you are using an active run.\n",
            "  lambda data: self._console_raw_callback(\"stderr\", data),\n",
            "Steps: 100% 15000/15000 [20:28:49<00:00,  4.92s/it, lr=0, step_loss=0.0516]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!accelerate launch --mixed_precision=\"fp16\"  train_text_to_image_lora.py \\\n",
        "  --pretrained_model_name_or_path=\"criminal-sketch-lora-v2-1\" \\\n",
        "  --dataset_name=\"SujinHwang/criminal-sketch-Hr\" \\\n",
        "  --dataloader_num_workers=8 \\\n",
        "  --resolution=512 --center_crop \\\n",
        "  --train_batch_size=1 \\\n",
        "  --gradient_accumulation_steps=4 \\\n",
        "  --num_train_epochs=3 \\\n",
        "  --max_train_steps=15000  \\\n",
        "  --learning_rate=1e-04 \\\n",
        "  --max_grad_norm=1 \\\n",
        "  --lr_scheduler=\"cosine\" --lr_warmup_steps=0 \\\n",
        "  --scale_lr \\\n",
        "  --output_dir=\"criminal-sketch-lora-v2-2\" \\\n",
        "  --push_to_hub \\\n",
        "  --report_to=wandb \\\n",
        "  --checkpointing_steps=15000 \\\n",
        "  --validation_prompt=\"ÎÇ®ÏÑ±. 30ÎåÄ. ÏñºÍµ¥ÏùÄ Í≥ÑÎûÄÌòïÏù¥Í≥† ÌÑ±ÏùÄ Îë•Í∑ºÌòïÏù¥Îã§. Í¥ëÎåÄÍ∞Ä ÎÇòÏôîÎã§. ÏßßÏùÄ Î®∏Î¶¨Ïù¥Í≥† ÎààÏçπÏù¥ ÏßÑÌïòÍ≥† ÏûëÏùÄ ÎààÏóê ÌåîÏûêÏ£ºÎ¶ÑÏù¥ ÏûàÎã§. \"   \\\n",
        "  --seed=8888"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ie1D8cIPif-E"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kxn8XMk7ifn6"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
